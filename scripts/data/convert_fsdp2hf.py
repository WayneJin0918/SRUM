# -*- coding: utf-8 -*-
import os
import torch
import shutil
from safetensors.torch import load_file, save_file
from tqdm import tqdm
import time
import concurrent.futures

# --- è·¯å¾„å’Œå‚æ•°é…ç½® ---
# åŒ…å«åŸå§‹æ£€æŸ¥ç‚¹çš„æºæ–‡ä»¶å¤¹è·¯å¾„
SOURCE_FOLDER = "results/checkpoint_2e7/0001000"

# åŒ…å«ä¸»æ¨¡å‹é…ç½®ã€åˆ†è¯å™¨ç­‰çš„æ–‡ä»¶å¤¹è·¯å¾„
MASTER_MODEL_FOLDER = "BAGEL-7B-MoT"

# ç”¨äºå­˜æ”¾å¤„ç†åæ–‡ä»¶çš„ç›®æ ‡æ–‡ä»¶å¤¹è·¯å¾„ (ç”¨äºè¯„ä¼°)
TARGET_FOLDER = "results/checkpoint_2e7/for_eval"

# å®Œæ•´ EMA æ¨¡å‹çš„è·¯å¾„ï¼Œç”¨äºè¡¥å…¨ç¼ºå¤±çš„æƒé‡
MASTER_EMA_PATH = os.path.join(MASTER_MODEL_FOLDER, "ema.safetensors")

# éœ€è¦è¢«è½¬æ¢ä¸º bfloat16 çš„æ–‡ä»¶å
FILES_TO_CONVERT = {"model.safetensors", "ema.safetensors"}

# å¹¶è¡Œå¤„ç†æ—¶ä½¿ç”¨çš„æœ€å¤§è¿›ç¨‹æ•° (None è¡¨ç¤ºä½¿ç”¨æ‰€æœ‰å¯ç”¨çš„ CPUæ ¸å¿ƒ)
MAX_WORKERS = None #å¯ä»¥è®¾ç½®ä¸ºå…·ä½“çš„æ•°å­—ï¼Œä¾‹å¦‚ 4

# --- å·¥ä½œå‡½æ•° (ç”¨äºå¹¶è¡Œå¤„ç†) ---

def convert_file_to_bf16(file_info):
    """
    åœ¨å•ä¸ªè¿›ç¨‹ä¸­è½¬æ¢å•ä¸ªæ–‡ä»¶åˆ° bfloat16 æ ¼å¼ã€‚
    è¿™æ˜¯ä¸€ä¸ªç‹¬ç«‹çš„å‡½æ•°ï¼Œä»¥ä¾¿äºå¹¶è¡ŒåŒ–ã€‚
    
    å‚æ•°:
        file_info (tuple): åŒ…å« (filename, source_folder, target_folder) çš„å…ƒç»„ã€‚
        
    è¿”å›:
        str: æè¿°æ“ä½œç»“æœçš„æ¶ˆæ¯ã€‚
    """
    filename, source_folder, target_folder = file_info
    source_path = os.path.join(source_folder, filename)
    target_path = os.path.join(target_folder, filename)
    
    try:
        # åŠ è½½æƒé‡æ–‡ä»¶åˆ° CPUï¼Œé¿å…å ç”¨ GPU æ˜¾å­˜
        tensors = load_file(source_path, device="cpu")
        tensors_bf16 = {}
        
        # ä½¿ç”¨ tqdm æ˜¾ç¤ºå•ä¸ªæ–‡ä»¶å†…éƒ¨å¼ é‡çš„è½¬æ¢è¿›åº¦
        # leave=False è¡¨ç¤ºå®Œæˆåè¿›åº¦æ¡ä¼šæ¶ˆå¤±
        item_iterator = tqdm(tensors.items(), desc=f"  -> è½¬æ¢ '{filename}'", leave=False, position=1)
        for k, v in item_iterator:
            # å°†å¼ é‡è½¬æ¢ä¸º bfloat16 ç±»å‹
            tensors_bf16[k] = v.to(torch.bfloat16)
        
        # ä¿å­˜è½¬æ¢åçš„æ–‡ä»¶
        save_file(tensors_bf16, target_path)
        return f"âœ… [å­è¿›ç¨‹] æˆåŠŸè½¬æ¢å¹¶ä¿å­˜: '{target_path}'"
        
    except Exception as e:
        return f"âŒ [å­è¿›ç¨‹] å¤„ç† '{filename}' æ—¶å‘ç”Ÿé”™è¯¯: {e}"


# --- ä¸»è„šæœ¬ ---

def main():
    """
    æ‰§è¡Œæ¨¡å‹è½¬æ¢å’Œæƒé‡è¡¥å…¨å…¨æµç¨‹çš„ä¸»å‡½æ•°ã€‚
    """
    start_time = time.time()
    print("ğŸš€ å¼€å§‹æ‰§è¡Œæ¨¡å‹å¤„ç†è„šæœ¬ (å¹¶è¡ŒåŠ é€Ÿç‰ˆ)...")
    print(f"æºæ£€æŸ¥ç‚¹æ–‡ä»¶å¤¹: {SOURCE_FOLDER}")
    print(f"æºä¸»æ¨¡å‹æ–‡ä»¶å¤¹: {MASTER_MODEL_FOLDER}")
    print(f"ç›®æ ‡æ–‡ä»¶å¤¹: {TARGET_FOLDER}")
    print("-" * 60)

    # ç¡®ä¿ç›®æ ‡æ–‡ä»¶å¤¹å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º
    os.makedirs(TARGET_FOLDER, exist_ok=True)

    # --- æ­¥éª¤ 1: å¤åˆ¶é…ç½®æ–‡ä»¶å’Œåˆ†è¯å™¨ç­‰éæƒé‡æ–‡ä»¶ ---
    print("\n--- æ­¥éª¤ 1: å¤åˆ¶éæƒé‡æ–‡ä»¶ (å¦‚ config, tokenizer) ---")
    try:
        master_model_files = os.listdir(MASTER_MODEL_FOLDER)
        
        # ä½¿ç”¨ tqdm æ˜¾ç¤ºæ–‡ä»¶å¤åˆ¶è¿›åº¦
        copy_iterator = tqdm(master_model_files, desc="å¤åˆ¶éæƒé‡æ–‡ä»¶")
        
        copied_count = 0
        for filename in copy_iterator:
            # è·³è¿‡æ‰€æœ‰æƒé‡æ–‡ä»¶ï¼Œåªå¤åˆ¶å…¶ä»–ç±»å‹æ–‡ä»¶
            if filename.endswith('ema.safetensors'):
                continue

            src_path = os.path.join(MASTER_MODEL_FOLDER, filename)
            dst_path = os.path.join(TARGET_FOLDER, filename)
            
            # ç¡®ä¿æˆ‘ä»¬æ­£åœ¨å¤åˆ¶çš„æ˜¯æ–‡ä»¶ï¼Œè€Œä¸æ˜¯å­ç›®å½•
            if os.path.isfile(src_path):
                shutil.copy2(src_path, dst_path)
                copied_count += 1
        
        print(f"âœ… æˆåŠŸå¤åˆ¶ {copied_count} ä¸ªéæƒé‡æ–‡ä»¶åˆ° '{TARGET_FOLDER}'")

    except FileNotFoundError:
        print(f"âŒ é”™è¯¯: Master æ¨¡å‹æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {MASTER_MODEL_FOLDER}")
    except Exception as e:
        print(f"âŒ åœ¨å¤åˆ¶æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")

    print("\n--- æ­¥éª¤ 1 å®Œæˆ ---")
    print("-" * 60)


    # --- æ­¥éª¤ 2: å¹¶è¡Œå°†æŒ‡å®šæ–‡ä»¶è½¬æ¢ä¸º bfloat16 æ ¼å¼ ---
    print("\n--- æ­¥éª¤ 2: å¹¶è¡Œè½¬æ¢æƒé‡æ–‡ä»¶åˆ° bfloat16 ---")
    
    try:
        all_source_files = os.listdir(SOURCE_FOLDER)
    except FileNotFoundError:
        print(f"âŒ é”™è¯¯: æºæ£€æŸ¥ç‚¹æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {SOURCE_FOLDER}")
        return

    # ç­›é€‰å‡ºéœ€è¦è½¬æ¢çš„æ–‡ä»¶
    files_to_process = [f for f in all_source_files if f in FILES_TO_CONVERT]
    
    if not files_to_process:
        print("ğŸŸ¡ åœ¨æºæ£€æŸ¥ç‚¹æ–‡ä»¶å¤¹ä¸­æœªæ‰¾åˆ°éœ€è¦è½¬æ¢çš„æƒé‡æ–‡ä»¶ã€‚")
    else:
        tasks = [(filename, SOURCE_FOLDER, TARGET_FOLDER) for filename in files_to_process]
        print(f"ğŸ“¨ å°† {len(tasks)} ä¸ªæƒé‡æ–‡ä»¶è½¬æ¢ä»»åŠ¡æäº¤åˆ°è¿›ç¨‹æ± ...")

        with concurrent.futures.ProcessPoolExecutor(max_workers=MAX_WORKERS) as executor:
            results = list(tqdm(executor.map(convert_file_to_bf16, tasks), total=len(tasks), desc="å¹¶è¡Œè½¬æ¢è¿›åº¦"))
        
        print("\n--- å¹¶è¡Œè½¬æ¢ç»“æœ ---")
        for res in results:
            print(res)
        print("----------------------")

    print("\n--- æ­¥éª¤ 2 å®Œæˆ ---")
    print("-" * 60)

    # --- æ­¥éª¤ 3: ä¸º model.safetensors è¡¥å…¨ç¼ºå¤±çš„æƒé‡ ---
    print("\n--- æ­¥éª¤ 3: ä¸º model.safetensors è¡¥å…¨ç¼ºå¤±çš„æƒé‡ ---")
    
    target_model_path = os.path.join(TARGET_FOLDER, "model.safetensors")
    
    if not os.path.exists(target_model_path):
        print(f"âš ï¸  è­¦å‘Š: ç›®æ ‡æ¨¡å‹ '{target_model_path}' ä¸å­˜åœ¨ã€‚è·³è¿‡æƒé‡è¡¥å…¨æ­¥éª¤ã€‚")
    elif not os.path.exists(MASTER_EMA_PATH):
        print(f"âš ï¸  è­¦å‘Š: æƒé‡æ¥æº (Master) '{MASTER_EMA_PATH}' ä¸å­˜åœ¨ã€‚è·³è¿‡æƒé‡è¡¥å…¨æ­¥éª¤ã€‚")
    else:
        try:
            print("æ­£åœ¨åŠ è½½ Master æ¨¡å‹å’Œç›®æ ‡æ¨¡å‹...")
            master_ema_tensors = load_file(MASTER_EMA_PATH, device="cpu")
            target_model_tensors = load_file(target_model_path, device="cpu")

            master_keys = set(master_ema_tensors.keys())
            target_keys = set(target_model_tensors.keys())
            
            missing_keys = master_keys - target_keys

            if not missing_keys:
                print("âœ… 'model.safetensors' ä¸­çš„æƒé‡æ˜¯å®Œæ•´çš„ï¼Œæ— éœ€è¡¥å…¨ã€‚")
            else:
                print(f"ğŸŸ¡ å‘ç° {len(missing_keys)} ä¸ªç¼ºå¤±çš„æƒé‡ï¼Œç°åœ¨å¼€å§‹è¡¥å…¨...")
                
                merged_tensors = target_model_tensors.copy()

                key_iterator = tqdm(sorted(list(missing_keys)), desc="  -> è¡¥å…¨ç¼ºå¤±çš„æƒé‡")
                for key in key_iterator:
                    merged_tensors[key] = master_ema_tensors[key].to(torch.bfloat16)
                
                print(f"ğŸ’¾ æ­£åœ¨ä¿å­˜è¡¥å…¨åçš„æ¨¡å‹ï¼Œæ€»æƒé‡æ•°: {len(merged_tensors)}...")
                save_file(merged_tensors, target_model_path)
                print(f"âœ… æˆåŠŸè¡¥å…¨å¹¶ä¿å­˜è‡³: '{target_model_path}'")

        except Exception as e:
            print(f"âŒ åœ¨æƒé‡è¡¥å…¨è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")

    print("\n--- æ­¥éª¤ 3 å®Œæˆ ---")
    print("-" * 60)

    end_time = time.time()
    print(f"ğŸ‰ æ‰€æœ‰ä»»åŠ¡å·²å®Œæˆï¼Œæ€»è€—æ—¶: {end_time - start_time:.2f} ç§’ã€‚")
    
    flag_path = os.path.join(TARGET_FOLDER, "processing_complete.txt")
    with open(flag_path, "w", encoding="utf-8") as f:
        f.write(f"å¤„ç†å®Œæˆäº: {time.ctime()}.\n")
        f.write("å·²å¤åˆ¶æ‰€æœ‰éæƒé‡æ–‡ä»¶ã€‚\n")
        f.write(f"å·²å°† {FILES_TO_CONVERT} è½¬æ¢ä¸º bfloat16 æ ¼å¼ã€‚\n")
        f.write("å·²ä½¿ç”¨ Master EMA æ¨¡å‹è¡¥å…¨äº† model.safetensors çš„æƒé‡ã€‚\n")
    print(f"ğŸ“„ å·²åˆ›å»ºæ ‡è®°æ–‡ä»¶: '{flag_path}'")


if __name__ == "__main__":
    # åœ¨ Windows æˆ– macOS ä¸Šä½¿ç”¨ 'spawn' æˆ– 'forkserver' å¯åŠ¨æ–¹å¼æ—¶ï¼Œ
    # å¿…é¡»å°†ä¸»é€»è¾‘ä»£ç æ”¾åœ¨ if __name__ == "__main__": å—å†…ã€‚
    try:
        torch.multiprocessing.set_start_method('spawn', force=True)
    except RuntimeError:
        # å¦‚æœå¯åŠ¨æ–¹æ³•å·²ç»è®¾ç½®ï¼Œåˆ™å¿½ç•¥é”™è¯¯
        pass
    main()
