import json
import argparse
from pathlib import Path
from tqdm import tqdm

# --- 3. 修改核心处理函数 ---
# 添加了一个新的参数 prompt_map，用于接收预加载的原始 prompt 数据
def parse_and_convert_record(record: dict, prompt_map: dict) -> dict | None:
    """
    Processes a single JSON record from the new analysis script.
    
    This version processes both regional rewards ('vlm_rewards') and the new
    global layout reward ('global_layout_reward') and combines them into a
    single list for training purposes.
    
    It now filters out records where the global layout reward score is 0.
    
    Args:
        record (dict): A single JSON object from the analysis output jsonl file.
        prompt_map (dict): A dictionary mapping 'image_file' to its original prompt.

    Returns:
        dict | None: A new formatted JSON object for training, or None on failure.
    """
    try:
        # --- 1. Extract Core Information & Get Original Prompt ---
        bad_image_file = record['image_file']
        good_image_file = record['image_file']
        
        # MODIFIED: 不再从当前 record 读取 prompt
        # prompt = record['prompt']
        
        # MODIFIED: 从预加载的 prompt_map 中通过 image_file 查找原始 prompt
        original_prompt = prompt_map.get(bad_image_file)
        
        # 如果在原始数据中找不到对应的 prompt，则跳过此记录
        if not original_prompt:
            # print(f"Warning: Original prompt for '{bad_image_file}' not found in the original source file. Skipping.")
            return None
            
        prompt = original_prompt # 确保后续代码可以使用 'prompt' 变量

        # --- 2. Process Global Layout Reward (NEW) and Filter ---
        global_layout_reward_data = record.get('global_layout_reward')
        global_score = None

        if global_layout_reward_data and 'global_layout_score' in global_layout_reward_data:
            global_score = global_layout_reward_data['global_layout_score']
            if global_score == 0:
                # print(f"Skipping record for {bad_image_file} due to global_layout_score = 0.")
                return None
        
        final_rewards = []
        if global_score is not None:
            global_bbox = global_layout_reward_data.get('bbox', [0, 0, 0, 0])
            final_rewards.append({
                "object": "global_layout_reward",
                "bbox": global_bbox,
                "score": global_score,
                "reason": global_layout_reward_data.get('reason', '')
            })

        # --- 3. Process Regional Rewards ---
        source_rewards = record.get('vlm_rewards', [])
        for reward_item in source_rewards:
            if not all(k in reward_item for k in ['identified_object', 'bbox', 'score']):
                continue
            
            final_rewards.append({
                "object": reward_item['identified_object'],
                "bbox": reward_item['bbox'],
                "score": reward_item['score']
            })

        if not final_rewards:
            return None

        # --- 4. Build the Final Output JSON ---
        final_record = {
            "bad_image_file": bad_image_file,
            "good_image_file": good_image_file,
            "prompt": prompt,
            "vlm_rewards": final_rewards
        }
        return final_record

    except KeyError as e:
        print(f"Warning: Record missing an essential key: {e}. Skipping record: {record}")
        return None
    except Exception as e:
        print(f"Warning: An unexpected error occurred while processing a record. Error: {e}. Skipping record.")
        return None

def main():
    parser = argparse.ArgumentParser(
        description="Convert pre-processed VLM analysis JSONL to a final, clean training format for regional rewards."
    )
    parser.add_argument(
        "--input_jsonl", type=str, required=True,
        help="Path to the source JSONL file generated by the new vlm_analysis.py."
    )
    # --- 1. 添加新的命令行参数 ---
    # 这个参数指向包含最原始 prompt 的文件
    parser.add_argument(
        "--original_jsonl", type=str, required=True,
        help="Path to the original JSONL file containing the pristine prompts."
    )
    parser.add_argument(
        "--output_jsonl", type=str, required=True,
        help="Path to save the converted and cleaned JSONL file for training."
    )
    args = parser.parse_args()

    input_path = Path(args.input_jsonl)
    original_path = Path(args.original_jsonl) # 新增
    output_path = Path(args.output_jsonl)

    if not input_path.exists():
        raise FileNotFoundError(f"Input file not found: {input_path}")
    if not original_path.exists(): # 新增
        raise FileNotFoundError(f"Original prompt file not found: {original_path}")

    # --- 2. 预加载原始的 Prompt ---
    # 创建一个字典来存储 image_file -> prompt 的映射
    print(f"Pre-loading original prompts from {original_path}...")
    prompt_map = {}
    with open(original_path, 'r', encoding='utf-8') as f:
        for line in f:
            try:
                original_record = json.loads(line)
                image_file = original_record.get('image_file')
                # 采用与分析脚本一致的逻辑来获取 prompt
                prompt_text = original_record.get('original_prompt')
                
                if image_file and prompt_text:
                    prompt_map[image_file] = prompt_text
            except json.JSONDecodeError:
                continue # 跳过格式错误的行
    print(f"Loaded {len(prompt_map)} original prompts into memory.")


    input_records_list = []
    with open(input_path, 'r', encoding='utf-8') as f:
        try:
            input_records_list = [json.loads(line) for line in f]
            print(f"Found {len(input_records_list)} records to process from {input_path}.")
        except json.JSONDecodeError as e:
            print(f"Error reading JSONL file: {e}. Please check file format.")
            return

    with open(output_path, 'w', encoding='utf-8') as f_out:
        processed_count = 0
        # 将 prompt_map 传入处理函数
        for record in tqdm(input_records_list, desc="Converting records"):
            converted_record = parse_and_convert_record(record, prompt_map) # 传入 map
            if converted_record:
                f_out.write(json.dumps(converted_record, ensure_ascii=False) + '\n')
                processed_count += 1
    
    print(f"Conversion complete. {processed_count} valid records saved to {output_path}")

if __name__ == "__main__":
    main()